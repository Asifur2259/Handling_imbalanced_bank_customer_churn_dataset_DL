{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\datasets\\Bank_Customer_Churn_Modelling.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('RowNumber', axis= 'columns', inplace=True)\n",
    "df.drop('CustomerId', axis= 'columns', inplace=True)\n",
    "df.drop('Surname', axis= 'columns', inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_col_values(df):\n",
    "    for column in df:\n",
    "        if df[column].dtypes=='object':\n",
    "            print(f'{column} : {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "uni_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':1, 'Male':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : [1 0]\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
       "       'Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography'])\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Gender                 int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_France       uint8\n",
       "Geography_Germany      uint8\n",
       "Geography_Spain        uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Gender : [1 0]\n",
      "Age : [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure : [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance : [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts : [0.         0.66666667 0.33333333 1.        ]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited : [1 0]\n",
      "Geography_France : [1 0]\n",
      "Geography_Germany : [0 1]\n",
      "Geography_Spain : [0 1]\n"
     ]
    }
   ],
   "source": [
    "for col in df1:\n",
    "    print(f'{col} : {df1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender    Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
       "0           False   False  False   False    False          False      False   \n",
       "1           False   False  False   False    False          False      False   \n",
       "2           False   False  False   False    False          False      False   \n",
       "3           False   False  False   False    False          False      False   \n",
       "4           False   False  False   False    False          False      False   \n",
       "...           ...     ...    ...     ...      ...            ...        ...   \n",
       "9995        False   False  False   False    False          False      False   \n",
       "9996        False   False  False   False    False          False      False   \n",
       "9997        False   False  False   False    False          False      False   \n",
       "9998        False   False  False   False    False          False      False   \n",
       "9999        False   False  False   False    False          False      False   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0              False            False   False             False   \n",
       "1              False            False   False             False   \n",
       "2              False            False   False             False   \n",
       "3              False            False   False             False   \n",
       "4              False            False   False             False   \n",
       "...              ...              ...     ...               ...   \n",
       "9995           False            False   False             False   \n",
       "9996           False            False   False             False   \n",
       "9997           False            False   False             False   \n",
       "9998           False            False   False             False   \n",
       "9999           False            False   False             False   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                 False            False  \n",
       "1                 False            False  \n",
       "2                 False            False  \n",
       "3                 False            False  \n",
       "4                 False            False  \n",
       "...                 ...              ...  \n",
       "9995              False            False  \n",
       "9996              False            False  \n",
       "9997              False            False  \n",
       "9998              False            False  \n",
       "9999              False            False  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1595\n",
       "1     405\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(12, input_dim=12, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 1ms/step - loss: 0.5120 - accuracy: 0.7972\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 906us/step - loss: 0.4665 - accuracy: 0.7991\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 928us/step - loss: 0.4692 - accuracy: 0.7884\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.4470 - accuracy: 0.7962\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 879us/step - loss: 0.4431 - accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 858us/step - loss: 0.4297 - accuracy: 0.8127\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 867us/step - loss: 0.4309 - accuracy: 0.8159\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 885us/step - loss: 0.4248 - accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 854us/step - loss: 0.4222 - accuracy: 0.8175\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 809us/step - loss: 0.4070 - accuracy: 0.8258\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 788us/step - loss: 0.4073 - accuracy: 0.8287\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 977us/step - loss: 0.3853 - accuracy: 0.8432\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.3869 - accuracy: 0.8376\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 917us/step - loss: 0.3728 - accuracy: 0.8518\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.3718 - accuracy: 0.8464\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 885us/step - loss: 0.3655 - accuracy: 0.8478\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8577\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8543\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.3517 - accuracy: 0.8549\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 914us/step - loss: 0.3482 - accuracy: 0.8601\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 894us/step - loss: 0.3494 - accuracy: 0.8551\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 889us/step - loss: 0.3559 - accuracy: 0.8582\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 881us/step - loss: 0.3384 - accuracy: 0.8645\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 874us/step - loss: 0.3389 - accuracy: 0.8622\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 861us/step - loss: 0.3545 - accuracy: 0.8512\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 861us/step - loss: 0.3449 - accuracy: 0.8592\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 862us/step - loss: 0.3343 - accuracy: 0.8648\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 858us/step - loss: 0.3477 - accuracy: 0.8554\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 854us/step - loss: 0.3493 - accuracy: 0.8585\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 834us/step - loss: 0.3556 - accuracy: 0.8609\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 842us/step - loss: 0.3370 - accuracy: 0.8660\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 829us/step - loss: 0.3480 - accuracy: 0.8606\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 865us/step - loss: 0.3535 - accuracy: 0.8559\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 811us/step - loss: 0.3359 - accuracy: 0.8621\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 834us/step - loss: 0.3351 - accuracy: 0.8640\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 850us/step - loss: 0.3507 - accuracy: 0.8577\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 862us/step - loss: 0.3354 - accuracy: 0.8599\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 851us/step - loss: 0.3351 - accuracy: 0.8646\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 838us/step - loss: 0.3372 - accuracy: 0.8626\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 818us/step - loss: 0.3404 - accuracy: 0.8649\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 912us/step - loss: 0.3428 - accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 901us/step - loss: 0.3453 - accuracy: 0.8601\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 890us/step - loss: 0.3346 - accuracy: 0.8693\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 855us/step - loss: 0.3439 - accuracy: 0.8626\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 905us/step - loss: 0.3383 - accuracy: 0.8636\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8588\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.3286 - accuracy: 0.8648\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 920us/step - loss: 0.3371 - accuracy: 0.8619\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.3363 - accuracy: 0.8635\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 949us/step - loss: 0.3418 - accuracy: 0.8605\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8635\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3341 - accuracy: 0.8628\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 783us/step - loss: 0.3264 - accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 757us/step - loss: 0.3386 - accuracy: 0.8612\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.3338 - accuracy: 0.8638\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 754us/step - loss: 0.3422 - accuracy: 0.8618\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3276 - accuracy: 0.8705\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 748us/step - loss: 0.3395 - accuracy: 0.8664\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3383 - accuracy: 0.8632\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 967us/step - loss: 0.3419 - accuracy: 0.8573\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3328 - accuracy: 0.8647\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8627\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 854us/step - loss: 0.3409 - accuracy: 0.8603\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8618\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8626\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8687\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8677\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8622\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 879us/step - loss: 0.3406 - accuracy: 0.8596\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 894us/step - loss: 0.3302 - accuracy: 0.8654\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 927us/step - loss: 0.3296 - accuracy: 0.8678\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 887us/step - loss: 0.3453 - accuracy: 0.8548\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 854us/step - loss: 0.3375 - accuracy: 0.8623\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 890us/step - loss: 0.3441 - accuracy: 0.8628\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 873us/step - loss: 0.3251 - accuracy: 0.8697\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 870us/step - loss: 0.3414 - accuracy: 0.8670\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 851us/step - loss: 0.3320 - accuracy: 0.8641\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 850us/step - loss: 0.3275 - accuracy: 0.8657\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 869us/step - loss: 0.3437 - accuracy: 0.8550\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 848us/step - loss: 0.3203 - accuracy: 0.8703\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 806us/step - loss: 0.3284 - accuracy: 0.8695\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 866us/step - loss: 0.3346 - accuracy: 0.8632\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8637\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 933us/step - loss: 0.3276 - accuracy: 0.8657\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 932us/step - loss: 0.3347 - accuracy: 0.8638\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 844us/step - loss: 0.3280 - accuracy: 0.8697\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 838us/step - loss: 0.3437 - accuracy: 0.8580\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 849us/step - loss: 0.3304 - accuracy: 0.8664\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 863us/step - loss: 0.3343 - accuracy: 0.8641\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 847us/step - loss: 0.3394 - accuracy: 0.8627\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 810us/step - loss: 0.3480 - accuracy: 0.8578\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 876us/step - loss: 0.3233 - accuracy: 0.8648\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8618: 0s - loss: 0.3369 - accura\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8688\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 877us/step - loss: 0.3331 - accuracy: 0.8670\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8635\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 838us/step - loss: 0.3318 - accuracy: 0.8631\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.3228 - accuracy: 0.8663\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8515\n",
      "[0.34869977831840515, 0.8514999747276306]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1595\n",
      "           1       0.70      0.47      0.56       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.79      0.71      0.74      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cls_0, count_cls_1 = df.Exited.value_counts()\n",
    "\n",
    "df_cls_0 = df1[df1['Exited']==0]\n",
    "df_cls_1 = df1[df1['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_cls_0, count_cls_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_0.sample(count_cls_1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Under-sampling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_0_under = df_cls_0.sample(count_cls_1)\n",
    "\n",
    "df_test_under = pd.concat([df_cls_0_under, df_cls_1], axis=0)\n",
    "\n",
    "print('Random Under-sampling:')\n",
    "df_test_under.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under.drop('Exited', axis='columns')\n",
    "y = df_test_under['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1630\n",
       "0    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    408\n",
       "1    407\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.6826 - accuracy: 0.5656\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5958\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 975us/step - loss: 0.6561 - accuracy: 0.6143\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6241\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 931us/step - loss: 0.6311 - accuracy: 0.6475\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 984us/step - loss: 0.6307 - accuracy: 0.6430\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 977us/step - loss: 0.6083 - accuracy: 0.6842\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.6018 - accuracy: 0.6745\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.6829\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6883\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.6968\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.5775 - accuracy: 0.6922\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 980us/step - loss: 0.5776 - accuracy: 0.6888\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.5556 - accuracy: 0.7269\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.5681 - accuracy: 0.7192\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.5528 - accuracy: 0.7203\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 919us/step - loss: 0.5484 - accuracy: 0.7321\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 958us/step - loss: 0.5437 - accuracy: 0.7285\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 938us/step - loss: 0.5615 - accuracy: 0.7127\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 978us/step - loss: 0.5357 - accuracy: 0.7316\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 975us/step - loss: 0.5299 - accuracy: 0.7448\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5402 - accuracy: 0.7214\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5297 - accuracy: 0.7376\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.5405 - accuracy: 0.7270\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 935us/step - loss: 0.5228 - accuracy: 0.7398\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 943us/step - loss: 0.5158 - accuracy: 0.7560\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5309 - accuracy: 0.7260\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.5217 - accuracy: 0.7318\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 987us/step - loss: 0.5325 - accuracy: 0.7233\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 973us/step - loss: 0.5351 - accuracy: 0.7302\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 997us/step - loss: 0.5334 - accuracy: 0.7236\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 980us/step - loss: 0.5361 - accuracy: 0.7266\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 950us/step - loss: 0.5163 - accuracy: 0.7431\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 939us/step - loss: 0.5195 - accuracy: 0.7435\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5062 - accuracy: 0.7454\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 987us/step - loss: 0.5123 - accuracy: 0.7444\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7387\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5204 - accuracy: 0.7371\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 984us/step - loss: 0.5274 - accuracy: 0.7307\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7481\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7478\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7480\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7421\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5023 - accuracy: 0.7448\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7568\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 963us/step - loss: 0.5058 - accuracy: 0.7497\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5112 - accuracy: 0.7386\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7652\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7359\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7472\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 987us/step - loss: 0.5023 - accuracy: 0.7524\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7577\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7490\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7573\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 949us/step - loss: 0.4968 - accuracy: 0.7650\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 965us/step - loss: 0.5060 - accuracy: 0.7491\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 947us/step - loss: 0.4889 - accuracy: 0.7642\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.4904 - accuracy: 0.7577\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.4951 - accuracy: 0.7577\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 958us/step - loss: 0.5034 - accuracy: 0.7499\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7645\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 954us/step - loss: 0.4834 - accuracy: 0.7631\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 921us/step - loss: 0.4856 - accuracy: 0.7616\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 901us/step - loss: 0.4800 - accuracy: 0.7616\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.4891 - accuracy: 0.7592\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.4881 - accuracy: 0.7606\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.4797 - accuracy: 0.7626\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 961us/step - loss: 0.4757 - accuracy: 0.7639\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.4759 - accuracy: 0.7757\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.4823 - accuracy: 0.7690\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 997us/step - loss: 0.4699 - accuracy: 0.7676\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 991us/step - loss: 0.4687 - accuracy: 0.7715\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 930us/step - loss: 0.4634 - accuracy: 0.7689\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.4667 - accuracy: 0.7750\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 981us/step - loss: 0.4645 - accuracy: 0.7725\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 978us/step - loss: 0.4852 - accuracy: 0.7653\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 972us/step - loss: 0.4603 - accuracy: 0.7719\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7848\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 980us/step - loss: 0.4659 - accuracy: 0.7726\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 968us/step - loss: 0.4673 - accuracy: 0.7669\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 952us/step - loss: 0.4743 - accuracy: 0.7665\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7843\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 940us/step - loss: 0.4654 - accuracy: 0.7760\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 922us/step - loss: 0.4465 - accuracy: 0.7794\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.4466 - accuracy: 0.7876\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 961us/step - loss: 0.4570 - accuracy: 0.7730\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 969us/step - loss: 0.4496 - accuracy: 0.7805\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 956us/step - loss: 0.4533 - accuracy: 0.7735\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 936us/step - loss: 0.4515 - accuracy: 0.7940\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 961us/step - loss: 0.4626 - accuracy: 0.7730\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 938us/step - loss: 0.4616 - accuracy: 0.7803\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.4442 - accuracy: 0.7874\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 923us/step - loss: 0.4460 - accuracy: 0.7810\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.4392 - accuracy: 0.7919\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 965us/step - loss: 0.4452 - accuracy: 0.7841\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 935us/step - loss: 0.4523 - accuracy: 0.7764\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.4543 - accuracy: 0.7783\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.4511 - accuracy: 0.7704\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 954us/step - loss: 0.4511 - accuracy: 0.7802\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 892us/step - loss: 0.4433 - accuracy: 0.7874\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.4813 - accuracy: 0.7571\n",
      "[0.4813176691532135, 0.7570552229881287]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       408\n",
      "           1       0.77      0.73      0.75       407\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.76      0.76      0.76       815\n",
      "weighted avg       0.76      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_cls_0, count_cls_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_1.sample(count_cls_0, replace=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_1_over = df_cls_1.sample(count_cls_0, replace=True)\n",
    "\n",
    "df_test_over = pd.concat([df_cls_0, df_cls_1_over], axis=0)\n",
    "\n",
    "print('Random Over-sampling')\n",
    "df_test_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under.drop('Exited', axis='columns')\n",
    "y = df_test_under['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1630\n",
       "0    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    408\n",
       "1    407\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3259"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 1ms/step - loss: 0.6983 - accuracy: 0.4973\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.6205\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 979us/step - loss: 0.6469 - accuracy: 0.6159\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 911us/step - loss: 0.6269 - accuracy: 0.6492\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 911us/step - loss: 0.6199 - accuracy: 0.6578\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6782\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 930us/step - loss: 0.5928 - accuracy: 0.6854\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 925us/step - loss: 0.5950 - accuracy: 0.6842\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 934us/step - loss: 0.5886 - accuracy: 0.6896\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 931us/step - loss: 0.5764 - accuracy: 0.7015\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5796 - accuracy: 0.6993\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 940us/step - loss: 0.5773 - accuracy: 0.7040\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 920us/step - loss: 0.5810 - accuracy: 0.6926\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 912us/step - loss: 0.5676 - accuracy: 0.7133\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 987us/step - loss: 0.5626 - accuracy: 0.7155\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 958us/step - loss: 0.5670 - accuracy: 0.7074\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 932us/step - loss: 0.5699 - accuracy: 0.7166\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.5629 - accuracy: 0.7131\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 931us/step - loss: 0.5523 - accuracy: 0.7270\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5750 - accuracy: 0.7088\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5646 - accuracy: 0.7050\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7063\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7098\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7156\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7073\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 966us/step - loss: 0.5731 - accuracy: 0.7010\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.5529 - accuracy: 0.7246\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5514 - accuracy: 0.7313\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.5603 - accuracy: 0.7095\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 936us/step - loss: 0.5514 - accuracy: 0.7206\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7191\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 966us/step - loss: 0.5577 - accuracy: 0.7065\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 960us/step - loss: 0.5514 - accuracy: 0.7262\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5542 - accuracy: 0.7180\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 980us/step - loss: 0.5626 - accuracy: 0.7131\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 931us/step - loss: 0.5460 - accuracy: 0.7299\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5494 - accuracy: 0.7302\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 950us/step - loss: 0.5484 - accuracy: 0.7226\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 967us/step - loss: 0.5475 - accuracy: 0.7183\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 954us/step - loss: 0.5540 - accuracy: 0.7146\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.5555 - accuracy: 0.7192\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 918us/step - loss: 0.5505 - accuracy: 0.7218\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 935us/step - loss: 0.5536 - accuracy: 0.7214\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 938us/step - loss: 0.5522 - accuracy: 0.7182\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7220\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 967us/step - loss: 0.5396 - accuracy: 0.7281\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 980us/step - loss: 0.5477 - accuracy: 0.7179\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5412 - accuracy: 0.7242\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 950us/step - loss: 0.5362 - accuracy: 0.7300\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 990us/step - loss: 0.5486 - accuracy: 0.7223\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 938us/step - loss: 0.5381 - accuracy: 0.7306\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 928us/step - loss: 0.5499 - accuracy: 0.7189\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 987us/step - loss: 0.5302 - accuracy: 0.7238\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 909us/step - loss: 0.5338 - accuracy: 0.7350\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 892us/step - loss: 0.5373 - accuracy: 0.7265\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 891us/step - loss: 0.5249 - accuracy: 0.7344\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.5420 - accuracy: 0.7297\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.5536 - accuracy: 0.7036\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 974us/step - loss: 0.5276 - accuracy: 0.7386\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 915us/step - loss: 0.5266 - accuracy: 0.7251\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 913us/step - loss: 0.5220 - accuracy: 0.7344\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.5295 - accuracy: 0.7237\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 974us/step - loss: 0.5196 - accuracy: 0.7400\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 891us/step - loss: 0.5209 - accuracy: 0.7307\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.5187 - accuracy: 0.7382\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 954us/step - loss: 0.5222 - accuracy: 0.7222\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 901us/step - loss: 0.5227 - accuracy: 0.7345\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.5135 - accuracy: 0.7405\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 901us/step - loss: 0.5121 - accuracy: 0.7386\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7398\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 958us/step - loss: 0.5047 - accuracy: 0.7392\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.5060 - accuracy: 0.7484\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.4992 - accuracy: 0.7544\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.4835 - accuracy: 0.7506\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.4849 - accuracy: 0.7606\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 931us/step - loss: 0.5011 - accuracy: 0.7524\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 970us/step - loss: 0.4912 - accuracy: 0.7605\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 901us/step - loss: 0.4740 - accuracy: 0.7662\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 951us/step - loss: 0.4817 - accuracy: 0.7634\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 970us/step - loss: 0.4807 - accuracy: 0.7605\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 880us/step - loss: 0.4809 - accuracy: 0.7655\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 883us/step - loss: 0.4789 - accuracy: 0.7655\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 894us/step - loss: 0.4559 - accuracy: 0.7841\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 862us/step - loss: 0.4824 - accuracy: 0.7637\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 948us/step - loss: 0.4572 - accuracy: 0.7838\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 884us/step - loss: 0.4600 - accuracy: 0.7897\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 874us/step - loss: 0.4685 - accuracy: 0.7790\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 958us/step - loss: 0.4590 - accuracy: 0.7762\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 874us/step - loss: 0.4668 - accuracy: 0.7713\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 901us/step - loss: 0.4649 - accuracy: 0.7768\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 914us/step - loss: 0.4536 - accuracy: 0.7927\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 880us/step - loss: 0.4506 - accuracy: 0.7841\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 912us/step - loss: 0.4594 - accuracy: 0.7726\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 881us/step - loss: 0.4681 - accuracy: 0.7675\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 894us/step - loss: 0.4564 - accuracy: 0.7751\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 911us/step - loss: 0.4419 - accuracy: 0.7951\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 872us/step - loss: 0.4467 - accuracy: 0.7719\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 933us/step - loss: 0.4489 - accuracy: 0.7872\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.4545 - accuracy: 0.7862\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 911us/step - loss: 0.4527 - accuracy: 0.7752\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7571\n",
      "[0.48952925205230713, 0.7570552229881287]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       408\n",
      "           1       0.75      0.76      0.76       407\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.76      0.76      0.76       815\n",
      "weighted avg       0.76      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1593\n",
       "0    1593\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.6807 - accuracy: 0.5663\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 0s 955us/step - loss: 0.6220 - accuracy: 0.6668\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 0s 923us/step - loss: 0.5917 - accuracy: 0.6954\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 0s 891us/step - loss: 0.5552 - accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 0s 884us/step - loss: 0.5207 - accuracy: 0.7537\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 0s 920us/step - loss: 0.4950 - accuracy: 0.7671\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 0s 889us/step - loss: 0.4860 - accuracy: 0.7697\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 0s 877us/step - loss: 0.4814 - accuracy: 0.7705\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 0s 908us/step - loss: 0.4760 - accuracy: 0.7692\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7782\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7799\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7859\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 0s 963us/step - loss: 0.4561 - accuracy: 0.7848\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.7827\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4492 - accuracy: 0.7884\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7847\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7893\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 0s 914us/step - loss: 0.4485 - accuracy: 0.7835\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 0s 914us/step - loss: 0.4373 - accuracy: 0.7949\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 0s 892us/step - loss: 0.4440 - accuracy: 0.7934\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 0s 898us/step - loss: 0.4520 - accuracy: 0.7853\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 0s 926us/step - loss: 0.4496 - accuracy: 0.7878\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 0s 925us/step - loss: 0.4483 - accuracy: 0.7842\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 0s 929us/step - loss: 0.4427 - accuracy: 0.7892\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 0s 941us/step - loss: 0.4453 - accuracy: 0.7874\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 0s 910us/step - loss: 0.4472 - accuracy: 0.78720s - loss: 0.4465 - accu\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 0s 906us/step - loss: 0.4492 - accuracy: 0.7888\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 0s 926us/step - loss: 0.4427 - accuracy: 0.7900\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 0s 913us/step - loss: 0.4546 - accuracy: 0.7817\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 0s 939us/step - loss: 0.4515 - accuracy: 0.7875\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 0s 908us/step - loss: 0.4416 - accuracy: 0.7941\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 0s 896us/step - loss: 0.4494 - accuracy: 0.7916\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 0s 905us/step - loss: 0.4444 - accuracy: 0.7907\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 0s 898us/step - loss: 0.4460 - accuracy: 0.7913\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 0s 914us/step - loss: 0.4329 - accuracy: 0.8001\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 0s 916us/step - loss: 0.4497 - accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 0s 893us/step - loss: 0.4337 - accuracy: 0.7980\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 0s 929us/step - loss: 0.4468 - accuracy: 0.7871\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 0s 902us/step - loss: 0.4469 - accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 0s 886us/step - loss: 0.4497 - accuracy: 0.7838\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 0s 905us/step - loss: 0.4471 - accuracy: 0.7892\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 0s 905us/step - loss: 0.4469 - accuracy: 0.7878\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 0s 897us/step - loss: 0.4509 - accuracy: 0.7813\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 0s 922us/step - loss: 0.4455 - accuracy: 0.7896\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 0s 885us/step - loss: 0.4482 - accuracy: 0.7844\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 0s 903us/step - loss: 0.4395 - accuracy: 0.79350s - loss: 0.4386 - accuracy: 0.\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 0s 904us/step - loss: 0.4366 - accuracy: 0.7949\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 0s 890us/step - loss: 0.4510 - accuracy: 0.7886\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 0s 918us/step - loss: 0.4399 - accuracy: 0.7945\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 0s 938us/step - loss: 0.4383 - accuracy: 0.7898\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 0s 913us/step - loss: 0.4402 - accuracy: 0.7937\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 0s 952us/step - loss: 0.4482 - accuracy: 0.7854\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 0s 910us/step - loss: 0.4499 - accuracy: 0.7901\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 0s 909us/step - loss: 0.4527 - accuracy: 0.7824\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 0s 911us/step - loss: 0.4445 - accuracy: 0.7915\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 0s 909us/step - loss: 0.4448 - accuracy: 0.7913\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.7897\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 0s 981us/step - loss: 0.4412 - accuracy: 0.7881\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7904\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7882\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 0s 993us/step - loss: 0.4451 - accuracy: 0.7875\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 0s 980us/step - loss: 0.4396 - accuracy: 0.7900\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 0s 990us/step - loss: 0.4402 - accuracy: 0.7945\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 0s 972us/step - loss: 0.4432 - accuracy: 0.7873\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7924\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7943\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 0s 967us/step - loss: 0.4368 - accuracy: 0.7950\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7888\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7924\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 0s 978us/step - loss: 0.4475 - accuracy: 0.7820\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7922\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7882\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 0s 998us/step - loss: 0.4412 - accuracy: 0.7901\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 0s 962us/step - loss: 0.4432 - accuracy: 0.7901\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7919\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7914\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 0s 962us/step - loss: 0.4510 - accuracy: 0.7882\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 0s 875us/step - loss: 0.4393 - accuracy: 0.7901\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 0s 858us/step - loss: 0.4383 - accuracy: 0.7908\n",
      "Epoch 81/100\n",
      "399/399 [==============================] - 0s 858us/step - loss: 0.4345 - accuracy: 0.7958\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 0s 849us/step - loss: 0.4456 - accuracy: 0.7881\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 0s 872us/step - loss: 0.4430 - accuracy: 0.7898\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 0s 877us/step - loss: 0.4424 - accuracy: 0.7920\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 0s 852us/step - loss: 0.4403 - accuracy: 0.7877\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 0s 879us/step - loss: 0.4467 - accuracy: 0.7874\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 0s 854us/step - loss: 0.4423 - accuracy: 0.7893\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 0s 872us/step - loss: 0.4375 - accuracy: 0.7953\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 0s 869us/step - loss: 0.4311 - accuracy: 0.7999\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 0s 862us/step - loss: 0.4382 - accuracy: 0.7963\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 0s 859us/step - loss: 0.4423 - accuracy: 0.7904\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 0s 879us/step - loss: 0.4394 - accuracy: 0.7907\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 0s 859us/step - loss: 0.4372 - accuracy: 0.7926\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 0s 864us/step - loss: 0.4410 - accuracy: 0.7949\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 0s 887us/step - loss: 0.4406 - accuracy: 0.7900\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 0s 847us/step - loss: 0.4343 - accuracy: 0.7931\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 0s 907us/step - loss: 0.4410 - accuracy: 0.7883\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 0s 855us/step - loss: 0.4446 - accuracy: 0.7899\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 0s 851us/step - loss: 0.4389 - accuracy: 0.7899\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 0s 872us/step - loss: 0.4393 - accuracy: 0.7939\n",
      "100/100 [==============================] - 0s 884us/step - loss: 0.4285 - accuracy: 0.7925\n",
      "[0.42847904562950134, 0.792529821395874]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1593\n",
      "           1       0.80      0.79      0.79      1593\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6370\n",
       "1    1630\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_cls_0 = df2[df2.Exited==0]\n",
    "df2_cls_1 = df2[df2.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6370, 13), (1630, 13))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_cls_0.shape, df2_cls_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "    \n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/119 [==============================] - 2s 1ms/step - loss: 0.6741 - accuracy: 0.5880\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6212\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6556\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.6681\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.6766\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1000us/step - loss: 0.5857 - accuracy: 0.7012\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6876: 0s - loss: 0.5878 - accuracy: 0.68\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7039\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6995\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.6983\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 998us/step - loss: 0.5630 - accuracy: 0.7154\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 964us/step - loss: 0.5516 - accuracy: 0.7202\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7262\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 964us/step - loss: 0.5331 - accuracy: 0.7339\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 980us/step - loss: 0.5174 - accuracy: 0.7492\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7489\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7411\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7562\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7694\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7598\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7683\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 985us/step - loss: 0.4957 - accuracy: 0.7683\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7658\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7642\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7614\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7633\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 985us/step - loss: 0.4875 - accuracy: 0.7642\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7673\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7829\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7672\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7732\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7691\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7759\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7631\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7562\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7632\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7678\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7669\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7612\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7682\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7723\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7798\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7635\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7654\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7838\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7803\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7839\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7679\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7691\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 968us/step - loss: 0.4804 - accuracy: 0.7676\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7647\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7778\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7738\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 995us/step - loss: 0.4764 - accuracy: 0.7727\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7780\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7777\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7698\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 937us/step - loss: 0.4586 - accuracy: 0.7813\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 997us/step - loss: 0.4700 - accuracy: 0.7801\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 962us/step - loss: 0.4663 - accuracy: 0.7689\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7816\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7706\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7785\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 978us/step - loss: 0.4516 - accuracy: 0.7851\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7831\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 996us/step - loss: 0.4667 - accuracy: 0.7755\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 963us/step - loss: 0.4705 - accuracy: 0.7686\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 989us/step - loss: 0.4592 - accuracy: 0.7865\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 968us/step - loss: 0.4632 - accuracy: 0.7769\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7658\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 980us/step - loss: 0.4656 - accuracy: 0.7728\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7813\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 960us/step - loss: 0.4476 - accuracy: 0.7862\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7668\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 960us/step - loss: 0.4526 - accuracy: 0.7847\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 972us/step - loss: 0.4556 - accuracy: 0.7787\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 963us/step - loss: 0.4603 - accuracy: 0.7861\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7877\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 996us/step - loss: 0.4646 - accuracy: 0.7814\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7750\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 951us/step - loss: 0.4459 - accuracy: 0.7859\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 962us/step - loss: 0.4433 - accuracy: 0.7873\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 919us/step - loss: 0.4552 - accuracy: 0.7900\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 930us/step - loss: 0.4585 - accuracy: 0.7853\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 897us/step - loss: 0.4602 - accuracy: 0.7801\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 974us/step - loss: 0.4518 - accuracy: 0.7911\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 989us/step - loss: 0.4648 - accuracy: 0.7885\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 951us/step - loss: 0.4507 - accuracy: 0.7923\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 938us/step - loss: 0.4561 - accuracy: 0.7843\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 929us/step - loss: 0.4549 - accuracy: 0.7869\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 948us/step - loss: 0.4511 - accuracy: 0.7775\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 852us/step - loss: 0.4564 - accuracy: 0.7762\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 916us/step - loss: 0.4516 - accuracy: 0.7876\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 895us/step - loss: 0.4511 - accuracy: 0.7873\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 898us/step - loss: 0.4579 - accuracy: 0.7806\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 937us/step - loss: 0.4502 - accuracy: 0.7838\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 946us/step - loss: 0.4597 - accuracy: 0.7867\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 947us/step - loss: 0.4637 - accuracy: 0.7767\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 938us/step - loss: 0.4527 - accuracy: 0.7842\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 932us/step - loss: 0.4597 - accuracy: 0.7765\n",
      "63/63 [==============================] - 0s 919us/step - loss: 0.3885 - accuracy: 0.8170\n",
      "[0.38848599791526794, 0.8169999718666077]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      1593\n",
      "           1       0.54      0.70      0.61       407\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.77      0.75      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_cls_0, df2_cls_1, 0, 2150)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/119 [==============================] - 1s 1ms/step - loss: 0.6564 - accuracy: 0.6092\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6730\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.6799\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7081\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5902 - accuracy: 0.6915\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7194\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5902 - accuracy: 0.6935\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7078\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7173\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7229\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7180\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7197\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7186\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 832us/step - loss: 0.5578 - accuracy: 0.7315\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 847us/step - loss: 0.5440 - accuracy: 0.7262\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 772us/step - loss: 0.5517 - accuracy: 0.7270\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 754us/step - loss: 0.5498 - accuracy: 0.7246\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 886us/step - loss: 0.5323 - accuracy: 0.7395\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 796us/step - loss: 0.5340 - accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.7313\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7352\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 829us/step - loss: 0.5296 - accuracy: 0.7342\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 808us/step - loss: 0.5201 - accuracy: 0.7479\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7454\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7642\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 925us/step - loss: 0.5195 - accuracy: 0.7478\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 737us/step - loss: 0.5004 - accuracy: 0.7634\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 788us/step - loss: 0.5038 - accuracy: 0.7470\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 843us/step - loss: 0.4929 - accuracy: 0.7615\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 829us/step - loss: 0.4895 - accuracy: 0.7683\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 871us/step - loss: 0.4945 - accuracy: 0.7646\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 997us/step - loss: 0.4850 - accuracy: 0.7747\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7627\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7769\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 989us/step - loss: 0.4797 - accuracy: 0.7750\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 947us/step - loss: 0.4794 - accuracy: 0.7781\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 824us/step - loss: 0.4717 - accuracy: 0.7804\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7785\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 817us/step - loss: 0.4658 - accuracy: 0.7849\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7840\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7737\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 785us/step - loss: 0.4739 - accuracy: 0.7768\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7783\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7755\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 957us/step - loss: 0.4662 - accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 847us/step - loss: 0.4673 - accuracy: 0.7786\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 854us/step - loss: 0.4823 - accuracy: 0.7701\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 850us/step - loss: 0.4641 - accuracy: 0.7842\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 772us/step - loss: 0.4679 - accuracy: 0.7739\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 925us/step - loss: 0.4642 - accuracy: 0.7759\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 725us/step - loss: 0.4606 - accuracy: 0.7858\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 785us/step - loss: 0.4677 - accuracy: 0.7711\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 738us/step - loss: 0.4608 - accuracy: 0.7839\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 770us/step - loss: 0.4689 - accuracy: 0.7806\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 697us/step - loss: 0.4515 - accuracy: 0.7853\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 769us/step - loss: 0.4595 - accuracy: 0.7770\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 641us/step - loss: 0.4525 - accuracy: 0.7842\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 696us/step - loss: 0.4628 - accuracy: 0.7674\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 750us/step - loss: 0.4466 - accuracy: 0.7935\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 653us/step - loss: 0.4643 - accuracy: 0.7769\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 716us/step - loss: 0.4644 - accuracy: 0.7693\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 715us/step - loss: 0.4583 - accuracy: 0.7839\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 719us/step - loss: 0.4522 - accuracy: 0.7910\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 738us/step - loss: 0.4737 - accuracy: 0.7685\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 717us/step - loss: 0.4616 - accuracy: 0.7807\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 848us/step - loss: 0.4590 - accuracy: 0.7877\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 694us/step - loss: 0.4621 - accuracy: 0.7732\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 721us/step - loss: 0.4409 - accuracy: 0.7977\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 849us/step - loss: 0.4578 - accuracy: 0.7819\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 777us/step - loss: 0.4445 - accuracy: 0.7892\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 780us/step - loss: 0.4539 - accuracy: 0.7892\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 771us/step - loss: 0.4609 - accuracy: 0.7769\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 762us/step - loss: 0.4404 - accuracy: 0.7920\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 848us/step - loss: 0.4568 - accuracy: 0.7855\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 847us/step - loss: 0.4474 - accuracy: 0.7932\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 848us/step - loss: 0.4503 - accuracy: 0.7893\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 846us/step - loss: 0.4549 - accuracy: 0.7884\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 846us/step - loss: 0.4585 - accuracy: 0.7882\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 848us/step - loss: 0.4593 - accuracy: 0.7837\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 776us/step - loss: 0.4637 - accuracy: 0.7763\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 785us/step - loss: 0.4637 - accuracy: 0.7807\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 844us/step - loss: 0.4468 - accuracy: 0.7937\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 765us/step - loss: 0.4445 - accuracy: 0.7929\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 738us/step - loss: 0.4555 - accuracy: 0.7825\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 741us/step - loss: 0.4516 - accuracy: 0.7880\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 773us/step - loss: 0.4430 - accuracy: 0.7922\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 787us/step - loss: 0.4493 - accuracy: 0.7873\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 749us/step - loss: 0.4520 - accuracy: 0.7923\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 703us/step - loss: 0.4426 - accuracy: 0.7921\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7922\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 747us/step - loss: 0.4380 - accuracy: 0.7940\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 666us/step - loss: 0.4525 - accuracy: 0.7821\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 702us/step - loss: 0.4489 - accuracy: 0.7903\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 716us/step - loss: 0.4569 - accuracy: 0.7859\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 724us/step - loss: 0.4627 - accuracy: 0.7804\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 746us/step - loss: 0.4742 - accuracy: 0.7701\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 651us/step - loss: 0.4601 - accuracy: 0.7872\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 700us/step - loss: 0.4572 - accuracy: 0.7771\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 814us/step - loss: 0.4407 - accuracy: 0.7917\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 663us/step - loss: 0.4557 - accuracy: 0.7864\n",
      "63/63 [==============================] - 0s 951us/step - loss: 0.4033 - accuracy: 0.8105\n",
      "[0.4032803475856781, 0.8105000257492065]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      1593\n",
      "           1       0.52      0.73      0.61       407\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.72      0.78      0.74      2000\n",
      "weighted avg       0.84      0.81      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_cls_0, df2_cls_1, 2150, 4300)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.5566\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6428\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6557\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6714\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6838\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.7009\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6883\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.6992\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7091\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7078\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7121\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7346\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7205\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7297\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7396\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7384\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 0s 983us/step - loss: 0.5202 - accuracy: 0.7446\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7375\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7517\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 0s 971us/step - loss: 0.5048 - accuracy: 0.7531\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 0s 989us/step - loss: 0.5036 - accuracy: 0.7497\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 0s 997us/step - loss: 0.5012 - accuracy: 0.7567\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7614\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 0s 979us/step - loss: 0.4986 - accuracy: 0.7560\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7404\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7789\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7817\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 0s 989us/step - loss: 0.4825 - accuracy: 0.7718\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 0s 967us/step - loss: 0.4873 - accuracy: 0.7728\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7676\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7824\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7588\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7679\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7744\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7775\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7817\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7578\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7686\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7774\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7862\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7702\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7664\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7790\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 0s 997us/step - loss: 0.4715 - accuracy: 0.7716\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7842\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7811\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7697\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7847\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7734\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7856\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7732\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 0s 989us/step - loss: 0.4788 - accuracy: 0.7721\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7712\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 0s 976us/step - loss: 0.4527 - accuracy: 0.7889\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 0s 967us/step - loss: 0.4594 - accuracy: 0.7828\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 0s 925us/step - loss: 0.4695 - accuracy: 0.7692\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 0s 964us/step - loss: 0.4778 - accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 0s 980us/step - loss: 0.4749 - accuracy: 0.7720\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 0s 961us/step - loss: 0.4659 - accuracy: 0.7796\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 0s 937us/step - loss: 0.4573 - accuracy: 0.7818\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 0s 944us/step - loss: 0.4642 - accuracy: 0.7743\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 0s 970us/step - loss: 0.4720 - accuracy: 0.7746\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 0s 944us/step - loss: 0.4812 - accuracy: 0.7757\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 0s 970us/step - loss: 0.4587 - accuracy: 0.7742\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 0s 987us/step - loss: 0.4572 - accuracy: 0.7781\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 0s 979us/step - loss: 0.4708 - accuracy: 0.7703\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 0s 980us/step - loss: 0.4520 - accuracy: 0.7923\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 0s 954us/step - loss: 0.4493 - accuracy: 0.7880\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 0s 961us/step - loss: 0.4530 - accuracy: 0.7820\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 0s 961us/step - loss: 0.4701 - accuracy: 0.7782\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 0s 978us/step - loss: 0.4651 - accuracy: 0.7833\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 0s 969us/step - loss: 0.4672 - accuracy: 0.7707\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 0s 978us/step - loss: 0.4780 - accuracy: 0.7707\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 0s 989us/step - loss: 0.4596 - accuracy: 0.7815\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 0s 979us/step - loss: 0.4677 - accuracy: 0.7798\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 0s 971us/step - loss: 0.4636 - accuracy: 0.7806\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 0s 961us/step - loss: 0.4688 - accuracy: 0.7841\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 0s 970us/step - loss: 0.4731 - accuracy: 0.7749\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 0s 978us/step - loss: 0.4596 - accuracy: 0.7884\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 978us/step - loss: 0.4567 - accuracy: 0.7879\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 0s 919us/step - loss: 0.4556 - accuracy: 0.7821\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 0s 929us/step - loss: 0.4721 - accuracy: 0.7708\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 0s 912us/step - loss: 0.4581 - accuracy: 0.7800\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 0s 979us/step - loss: 0.4605 - accuracy: 0.7832\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7794\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7760\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7791\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7873\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7760\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7768\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7687\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 0s 985us/step - loss: 0.4721 - accuracy: 0.7781\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 0s 989us/step - loss: 0.4604 - accuracy: 0.7778\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7739\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7818\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 0s 996us/step - loss: 0.4651 - accuracy: 0.7806\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7705\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7609\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 0s 984us/step - loss: 0.4615 - accuracy: 0.7778\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7864\n",
      "63/63 [==============================] - 0s 888us/step - loss: 0.3991 - accuracy: 0.8175\n",
      "[0.39914631843566895, 0.8174999952316284]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88      1593\n",
      "           1       0.54      0.66      0.59       407\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.76      0.74      2000\n",
      "weighted avg       0.83      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_cls_0, df2_cls_1, 4300, 6370)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i]+y_pred2[i]+y_pred3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88      1593\n",
      "           1       0.53      0.69      0.60       407\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.72      0.77      0.74      2000\n",
      "weighted avg       0.84      0.81      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
